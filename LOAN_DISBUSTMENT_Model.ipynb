{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7f70010e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Snowpark lib\n",
    "from snowflake.snowpark import Session\n",
    "\n",
    "# Data Science Libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# create_temp_table warning suppresion\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "#ConfigParser to read ini file\n",
    "import configparser\n",
    "\n",
    "from fosforio import snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4e535644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>DOB</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>MONTHLY_INCOME</th>\n",
       "      <th>EMPLOYER_NAME</th>\n",
       "      <th>SALARY_ACCOUNT</th>\n",
       "      <th>LOAN_AMOUNT_APPLIED</th>\n",
       "      <th>...</th>\n",
       "      <th>QUARTER</th>\n",
       "      <th>MOBILE_VERIFIED</th>\n",
       "      <th>FILLED_FORM</th>\n",
       "      <th>DEVICE_TYPE</th>\n",
       "      <th>VAR2</th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>VAR4</th>\n",
       "      <th>VAR5</th>\n",
       "      <th>VAR1</th>\n",
       "      <th>DISBURSED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID000977Z13</td>\n",
       "      <td>Male</td>\n",
       "      <td>10/1/1988</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>36</td>\n",
       "      <td>1313.242865</td>\n",
       "      <td>Hcl Global Systems</td>\n",
       "      <td>Bank of Hope</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>E</td>\n",
       "      <td>S127</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14</td>\n",
       "      <td>HBXX</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID000626U25</td>\n",
       "      <td>Male</td>\n",
       "      <td>4/1/1992</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>32</td>\n",
       "      <td>1270.880192</td>\n",
       "      <td>Synechron</td>\n",
       "      <td>Bank of Marin</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Web-browser</td>\n",
       "      <td>G</td>\n",
       "      <td>S151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>HBXB</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID019473Z30</td>\n",
       "      <td>Male</td>\n",
       "      <td>02/1/1996</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>28</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>Syntel</td>\n",
       "      <td>Exchange Bank</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Web-browser</td>\n",
       "      <td>B</td>\n",
       "      <td>S144</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11</td>\n",
       "      <td>HBXC</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID000062G50</td>\n",
       "      <td>Male</td>\n",
       "      <td>3/6/1989</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>35</td>\n",
       "      <td>1497.000000</td>\n",
       "      <td>Uber Technologies</td>\n",
       "      <td>Bank of Marin</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Web-browser</td>\n",
       "      <td>B</td>\n",
       "      <td>S133</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>HAXB</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID000935I02</td>\n",
       "      <td>Female</td>\n",
       "      <td>30/8/1996</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>28</td>\n",
       "      <td>903.000000</td>\n",
       "      <td>Hcl America</td>\n",
       "      <td>CIT Bank</td>\n",
       "      <td>700000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Web-browser</td>\n",
       "      <td>B</td>\n",
       "      <td>S160</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>HBXX</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  GENDER        DOB      CITY     STATE  AGE  MONTHLY_INCOME  \\\n",
       "0  ID000977Z13    Male  10/1/1988  New York  New York   36     1313.242865   \n",
       "1  ID000626U25    Male   4/1/1992  New York  New York   32     1270.880192   \n",
       "2  ID019473Z30    Male  02/1/1996  New York  New York   28      500.000000   \n",
       "3  ID000062G50    Male   3/6/1989  New York  New York   35     1497.000000   \n",
       "4  ID000935I02  Female  30/8/1996  New York  New York   28      903.000000   \n",
       "\n",
       "        EMPLOYER_NAME SALARY_ACCOUNT  LOAN_AMOUNT_APPLIED  ...  QUARTER  \\\n",
       "0  Hcl Global Systems   Bank of Hope             900000.0  ...        4   \n",
       "1           Synechron  Bank of Marin             900000.0  ...        2   \n",
       "2              Syntel  Exchange Bank              10000.0  ...        2   \n",
       "3   Uber Technologies  Bank of Marin             900000.0  ...        1   \n",
       "4         Hcl America       CIT Bank             700000.0  ...        4   \n",
       "\n",
       "   MOBILE_VERIFIED FILLED_FORM  DEVICE_TYPE  VAR2  SOURCE VAR4 VAR5  VAR1  \\\n",
       "0                Y           Y       Mobile     E    S127  7.0   14  HBXX   \n",
       "1                Y           N  Web-browser     G    S151  5.0   10  HBXB   \n",
       "2                Y           N  Web-browser     B    S144  4.0   11  HBXC   \n",
       "3                Y           Y  Web-browser     B    S133  4.0    0  HAXB   \n",
       "4                N           Y  Web-browser     B    S160  1.0    3  HBXX   \n",
       "\n",
       "  DISBURSED  \n",
       "0       1.0  \n",
       "1       1.0  \n",
       "2       0.0  \n",
       "3       1.0  \n",
       "4       0.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To read a specific dataset published from a snowflake connection\n",
    "df = snowflake.get_dataframe(\"MASTER\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "33436038",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.drop([\"ID\", \"LEAD_CREATION_DATE\", \"DEVICE_TYPE\", \"SALARY_ACCOUNT\", \"CITY\", \"DOB\", \"EMPLOYER_NAME\",\"YEAR\",\"QUARTER\",\"MONTH\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c4ce2e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GENDER</th>\n",
       "      <th>STATE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>MONTHLY_INCOME</th>\n",
       "      <th>LOAN_AMOUNT_APPLIED</th>\n",
       "      <th>LOAN_TENURE_APPLIED</th>\n",
       "      <th>EXISTING_EMI</th>\n",
       "      <th>MOBILE_VERIFIED</th>\n",
       "      <th>FILLED_FORM</th>\n",
       "      <th>VAR2</th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>VAR4</th>\n",
       "      <th>VAR5</th>\n",
       "      <th>VAR1</th>\n",
       "      <th>DISBURSED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>New York</td>\n",
       "      <td>36</td>\n",
       "      <td>1313.242865</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>E</td>\n",
       "      <td>S127</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14</td>\n",
       "      <td>HBXX</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>New York</td>\n",
       "      <td>32</td>\n",
       "      <td>1270.880192</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>G</td>\n",
       "      <td>S151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>HBXB</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>New York</td>\n",
       "      <td>28</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>B</td>\n",
       "      <td>S144</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11</td>\n",
       "      <td>HBXC</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>New York</td>\n",
       "      <td>35</td>\n",
       "      <td>1497.000000</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>B</td>\n",
       "      <td>S133</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>HAXB</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>New York</td>\n",
       "      <td>28</td>\n",
       "      <td>903.000000</td>\n",
       "      <td>700000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>B</td>\n",
       "      <td>S160</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>HBXX</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GENDER     STATE  AGE  MONTHLY_INCOME  LOAN_AMOUNT_APPLIED  \\\n",
       "0    Male  New York   36     1313.242865             900000.0   \n",
       "1    Male  New York   32     1270.880192             900000.0   \n",
       "2    Male  New York   28      500.000000              10000.0   \n",
       "3    Male  New York   35     1497.000000             900000.0   \n",
       "4  Female  New York   28      903.000000             700000.0   \n",
       "\n",
       "   LOAN_TENURE_APPLIED  EXISTING_EMI MOBILE_VERIFIED FILLED_FORM VAR2 SOURCE  \\\n",
       "0                  3.0         139.0               Y           Y    E   S127   \n",
       "1                  3.0           0.0               Y           N    G   S151   \n",
       "2                  0.0         100.0               Y           N    B   S144   \n",
       "3                  3.0         140.0               Y           Y    B   S133   \n",
       "4                  3.0           0.0               N           Y    B   S160   \n",
       "\n",
       "   VAR4  VAR5  VAR1  DISBURSED  \n",
       "0   7.0    14  HBXX        1.0  \n",
       "1   5.0    10  HBXB        1.0  \n",
       "2   4.0    11  HBXC        0.0  \n",
       "3   4.0     0  HAXB        1.0  \n",
       "4   1.0     3  HBXX        0.0  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b4f6ea1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5e8b7789",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "99b11755",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b95e7b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col = []\n",
    "num_col = []\n",
    "target = \"DISBURSED\"\n",
    "\n",
    "for k, v in dict(data.dtypes).items():\n",
    "    if k != target:\n",
    "        if v == \"O\":\n",
    "            cat_col.append(k)\n",
    "        else:\n",
    "            num_col.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fa3a23e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "used_cols = [c for c in data.columns.tolist() if c not in [target]]\n",
    "X=df[used_cols]\n",
    "y=df[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b9f1fa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "db443bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# making pipeline\n",
    "scaler = RobustScaler()\n",
    "encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "# putting numeric columns to scaler and categorical to encoder\n",
    "num_transformer = make_pipeline(scaler)\n",
    "cat_transformer = make_pipeline(encoder)\n",
    "\n",
    "# getting together our scaler and encoder with preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "      transformers=[('num', num_transformer, num_col),\n",
    "                    ('cat', cat_transformer, cat_col)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d00f2d1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# giving all values to pipeline\u001b[39;00m\n\u001b[1;32m      5\u001b[0m pipe \u001b[38;5;241m=\u001b[39m make_pipeline(preprocessor,model_name)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/packages/Python-3.8-Snowpark/86595857-4c87-4db3-814d-b3b9191f5ae5/3.8/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/packages/Python-3.8-Snowpark/86595857-4c87-4db3-814d-b3b9191f5ae5/3.8/sklearn/pipeline.py:427\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    426\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 427\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/packages/Python-3.8-Snowpark/86595857-4c87-4db3-814d-b3b9191f5ae5/3.8/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/packages/Python-3.8-Snowpark/86595857-4c87-4db3-814d-b3b9191f5ae5/3.8/sklearn/ensemble/_forest.py:348\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 348\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    352\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[0;32m/packages/Python-3.8-Snowpark/86595857-4c87-4db3-814d-b3b9191f5ae5/3.8/sklearn/base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    620\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 622\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/packages/Python-3.8-Snowpark/86595857-4c87-4db3-814d-b3b9191f5ae5/3.8/sklearn/utils/validation.py:1146\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1143\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1144\u001b[0m     )\n\u001b[0;32m-> 1146\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1162\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1164\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m/packages/Python-3.8-Snowpark/86595857-4c87-4db3-814d-b3b9191f5ae5/3.8/sklearn/utils/validation.py:881\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sp\u001b[38;5;241m.\u001b[39missparse(array):\n\u001b[1;32m    880\u001b[0m     _ensure_no_complex_data(array)\n\u001b[0;32m--> 881\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_sparse_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    892\u001b[0m     \u001b[38;5;66;03m# If np.array(..) gives ComplexWarning, then we convert the warning\u001b[39;00m\n\u001b[1;32m    893\u001b[0m     \u001b[38;5;66;03m# to an error. This is needed because specifying a non complex\u001b[39;00m\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;66;03m# dtype to the function converts complex to real dtype,\u001b[39;00m\n\u001b[1;32m    895\u001b[0m     \u001b[38;5;66;03m# thereby passing the test made in the lines following the scope\u001b[39;00m\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;66;03m# of warnings context manager.\u001b[39;00m\n\u001b[1;32m    897\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n",
      "File \u001b[0;32m/packages/Python-3.8-Snowpark/86595857-4c87-4db3-814d-b3b9191f5ae5/3.8/sklearn/utils/validation.py:571\u001b[0m, in \u001b[0;36m_ensure_sparse_format\u001b[0;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    566\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    567\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt check \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m sparse matrix for nan or inf.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m spmatrix\u001b[38;5;241m.\u001b[39mformat,\n\u001b[1;32m    568\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    569\u001b[0m         )\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 571\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m            \u001b[49m\u001b[43mspmatrix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m spmatrix\n",
      "File \u001b[0;32m/packages/Python-3.8-Snowpark/86595857-4c87-4db3-814d-b3b9191f5ae5/3.8/sklearn/utils/validation.py:122\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/packages/Python-3.8-Snowpark/86595857-4c87-4db3-814d-b3b9191f5ae5/3.8/sklearn/utils/validation.py:171\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    170\u001b[0m     )\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "# choosing model\n",
    "model_name = RandomForestClassifier(n_estimators = 500, max_depth=8, random_state=25, max_samples=0.6)\n",
    "\n",
    "# giving all values to pipeline\n",
    "pipe = make_pipeline(preprocessor,model_name)\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8b3b7be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GENDER                 False\n",
       "STATE                  False\n",
       "AGE                    False\n",
       "MONTHLY_INCOME         False\n",
       "LOAN_AMOUNT_APPLIED     True\n",
       "LOAN_TENURE_APPLIED     True\n",
       "EXISTING_EMI            True\n",
       "MOBILE_VERIFIED        False\n",
       "FILLED_FORM            False\n",
       "VAR2                   False\n",
       "SOURCE                 False\n",
       "VAR4                   False\n",
       "VAR5                   False\n",
       "VAR1                   False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4966a234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on training set\n",
    "y_pred = pipe.predict(X_train)\n",
    "\n",
    "# make predictions on test set\n",
    "y_pred_test = pipe.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
